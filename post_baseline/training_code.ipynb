{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae494339",
   "metadata": {},
   "source": [
    "### Instruction\n",
    "- Start the mlflow server before running this code.\n",
    "\n",
    "- Change the IP address (tracking uri) accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ad885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "# connect the experiment to the tracking server \n",
    "# change the IP address accordingly\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5001\")\n",
    "\n",
    "# set the experiment name\n",
    "mlflow.set_experiment(\"post_baseline_EfficientNet\")\n",
    "\n",
    "# enable autologging\n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15187e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging to a file\n",
    "import logging\n",
    "\n",
    "# Get current working directory\n",
    "log_file_path = os.path.join(os.getcwd(), 'training.log')\n",
    "\n",
    "# Set up the logger manually\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Remove all previous handlers (important in Jupyter)\n",
    "logger.handlers.clear()\n",
    "\n",
    "# Create and add FileHandler\n",
    "file_handler = logging.FileHandler(log_file_path, mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Optional: also log to console\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd6b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 22:29:22,693 - INFO - MPS backend is available. It uses the global PyTorch seed.\n",
      "2025-08-19 22:29:22,694 - INFO - Deterministic algorithms set to True.\n",
      "2025-08-19 22:29:22,694 - INFO - Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "from utils.seed import set_seed\n",
    "# Set a global seed for reproducibility\n",
    "global_seed = 42\n",
    "set_seed(global_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7683d",
   "metadata": {},
   "source": [
    "### Instruction \n",
    "\n",
    "- Only the following cell requires changes inorder to swap models being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25449091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 22:29:22,804 - INFO - Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNetB0WithCosineHead(\n",
       "  (head): CNNPatchDownscaleHead(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1280, out_features=128, bias=True)\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): CosineClassifier()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes\n",
    "num_classes = 5  # change according to your dataset\n",
    "dropout = 0.5  # Set dropout rate\n",
    "# learning rates\n",
    "base_lr = 0.001          # head + classifier\n",
    "encoder_lr = base_lr*0.1  # encoder when unfrozen\n",
    "\n",
    "# ================================================================================\n",
    "# Model selection - change this section to swap models\n",
    "# ================================================================================\n",
    "from models_SICC.EfficientNet import EfficientNetB0WithCosineHead\n",
    "# Initialize the model\n",
    "model = EfficientNetB0WithCosineHead(num_classes, dropout)\n",
    "# ================================================================================\n",
    "\n",
    "\n",
    "# Check device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.backends.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "logging.info(f\"Using device: {device.type}\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38dddc4",
   "metadata": {},
   "source": [
    "### Parameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.regularization import EarlyStopping\n",
    "from utils.train_validate import train, validate\n",
    "from utils.transfer_learning import freeze_encoder, unfreeze_last_layers, get_optimizer\n",
    "\n",
    "# batch size\n",
    "dataloader_eval_batch = 8\n",
    "dataloader_train_batch = 8\n",
    "\n",
    "# Initialize optimizer\n",
    "starting_lr = base_lr\n",
    "optimizer = optimizer = get_optimizer(\n",
    "    model,\n",
    "    base_lr=starting_lr, \n",
    "    encoder_lr=0.0001, \n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',           # maximize validation accuracy or F1\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    cooldown=2,\n",
    "    min_lr=1e-6,\n",
    "    threshold=0.0001,\n",
    "    threshold_mode='abs',\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping_patience = scheduler.cooldown + scheduler.patience + 5\n",
    "early_stopping_delta = scheduler.threshold / 2\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=early_stopping_patience,\n",
    "    verbose=True,\n",
    "    min_delta=early_stopping_delta\n",
    ")\n",
    "\n",
    "unfreeze_encoder_at = 10\n",
    "max_num_epochs = 300\n",
    "\n",
    "\n",
    "\n",
    "# Log params to MLflow\n",
    "params = {\n",
    "    \"global_seed\": global_seed,\n",
    "    \"train_batch_size\": dataloader_train_batch,\n",
    "    \"eval_batch_size\": dataloader_eval_batch,\n",
    "    \"loss_function\": \"CrossEntropyLoss\",\n",
    "    \"learning_rate\": starting_lr,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler_mode\": \"max\",\n",
    "    \"scheduler_factor\": 0.5,\n",
    "    \"scheduler_patience\": 2,\n",
    "    \"scheduler_cooldown\": 0,\n",
    "    \"scheduler_min_lr\": 1e-6,\n",
    "    \"scheduler_threshold\": 0.0001,\n",
    "    \"scheduler_threshold_mode\": \"abs\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"early_stopping_patience\": early_stopping_patience,\n",
    "    \"early_stopping_delta\": early_stopping_delta,\n",
    "    \"max_epochs\": max_num_epochs,\n",
    "    \"device\": device.type,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"dropout\": dropout\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 22:29:23,048 - INFO - Train class counts: [320, 320, 801, 8000, 480]\n",
      "2025-08-19 22:29:23,048 - INFO - Val   class counts: [80, 80, 200, 2000, 120]\n",
      "2025-08-19 22:29:23,049 - INFO - ENS Train class weights: [1.5932106971740723, 1.5932106971740723, 0.6518386602401733, 0.0911238044500351, 1.070616602897644]\n",
      "2025-08-19 22:29:23,049 - INFO - ENS Val   class weights: [1.6054655313491821, 1.6054655313491821, 0.6460433602333069, 0.07057320326566696, 1.0724523067474365]\n",
      "2025-08-19 22:29:23,248 - INFO - Started MLflow run with ID: 27e44f7ad4874ddfbb9a6c7e07947f04\n",
      "2025-08-19 22:29:24,203 - INFO - Model report logged to MLflow\n",
      "2025-08-19 22:29:24,204 - INFO - Starting training...\n",
      "2025-08-19 22:29:24,205 - INFO -  Encoder frozen (training head + classifier only)\n",
      "2025-08-19 22:29:24,205 - INFO - Unfroze last 2 residual blocks of encoder.layer4\n",
      "2025-08-19 22:29:24,206 - INFO - Adjusted LR for encoder fine-tuning\n",
      "2025-08-19 22:29:24,212 - INFO - Epoch 1, Head LR: 0.001, Encoder LR: 0.0001\n",
      "Epoch 1 [Train]:   2%|▏         | 25/1240 [00:19<10:15,  1.97it/s, loss=0.735]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from utils.datasets import AugmentedDataset\n",
    "from utils.custom_sampler_and_loss import effective_num_weights, ClassBalancedFocalLoss\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "def main(num_workers=4):\n",
    "    input_transform = transforms.Compose([\n",
    "        transforms.Resize((720, 1270)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    ])\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(42)\n",
    "\n",
    "    # Load datasets\n",
    "    full_dataset = AugmentedDataset(\"augmented_data/train\", transform=input_transform)\n",
    "    test_dataset = AugmentedDataset(\"augmented_data/val\", transform=input_transform)\n",
    "\n",
    "\n",
    "    # ===== NEW: Extract labels directly =====\n",
    "    if hasattr(full_dataset, \"labels\"):\n",
    "        train_targets = np.array(full_dataset.labels)\n",
    "    elif hasattr(full_dataset, \"targets\"):\n",
    "        train_targets = np.array(full_dataset.targets)\n",
    "    else:\n",
    "        raise AttributeError(\"Your AugmentedDataset must store labels in .labels or .targets\")\n",
    "\n",
    "    if hasattr(test_dataset, \"labels\"):\n",
    "        val_targets = np.array(test_dataset.labels)\n",
    "    elif hasattr(test_dataset, \"targets\"):\n",
    "        val_targets = np.array(test_dataset.targets)\n",
    "    else:\n",
    "        raise AttributeError(\"Your AugmentedDataset must store labels in .labels or .targets\")\n",
    "\n",
    "    num_classes = len(np.unique(train_targets))\n",
    "\n",
    "    # ===== Compute class counts separately for train and val =====\n",
    "    train_class_counts = np.bincount(train_targets, minlength=num_classes)\n",
    "    val_class_counts   = np.bincount(val_targets, minlength=num_classes)\n",
    "\n",
    "    # ===== Compute ENS class weights =====\n",
    "    train_class_weights = effective_num_weights(train_class_counts, beta=0.9999, device=device)\n",
    "    val_class_weights   = effective_num_weights(val_class_counts, beta=0.9999, device=device)\n",
    "\n",
    "    logging.info(f\"Train class counts: {train_class_counts.tolist()}\")\n",
    "    logging.info(f\"Val   class counts: {val_class_counts.tolist()}\")\n",
    "    logging.info(f\"ENS Train class weights: {train_class_weights.tolist()}\")\n",
    "    logging.info(f\"ENS Val   class weights: {val_class_weights.tolist()}\")\n",
    "\n",
    "    # ===== Class-balanced Focal yLoss for train and val =====\n",
    "    train_criterion = ClassBalancedFocalLoss(train_class_counts, beta=0.9999, gamma=2.0, device=device)\n",
    "    val_criterion   = ClassBalancedFocalLoss(val_class_counts, beta=0.9999, gamma=2.0, device=device)\n",
    "\n",
    "\n",
    "    # Compute sample weights for WeightedRandomSampler (train only)\n",
    "    train_sample_weights = train_class_weights[train_targets]\n",
    "\n",
    "    # Compute sample weights for WeightedRandomSampler (val only)\n",
    "    val_sample_weights = val_class_weights[val_targets]\n",
    "\n",
    "    # IMPORTANT: move to CPU + float32 (MPS cannot handle float64)\n",
    "    train_sampler = WeightedRandomSampler(\n",
    "        weights     = train_sample_weights.cpu().to(torch.float32),\n",
    "        num_samples = len(train_sample_weights),\n",
    "        replacement = True\n",
    "    )\n",
    "\n",
    "    # Create the sampler for the validation set\n",
    "    val_sampler = WeightedRandomSampler(\n",
    "        weights     = val_sample_weights.cpu().to(torch.float32),\n",
    "        num_samples = len(val_sample_weights),\n",
    "        replacement = True\n",
    "    )\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        full_dataset,\n",
    "        batch_size=dataloader_train_batch,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "        shuffle=False,  \n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=dataloader_eval_batch,\n",
    "        sampler = val_sampler,\n",
    "        drop_last=True, \n",
    "        shuffle  = False,  # no need to shuffle validation data\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # ===== TRAINING LOOP =====\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        logging.info(f\"Started MLflow run with ID: {run_id}\")\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        try:\n",
    "            model_summary = summary(model, input_size=(1, 3, 720, 1270), device=device.type)\n",
    "\n",
    "            with open(\"model_report.txt\", \"w\") as f:\n",
    "                f.write(\"### MODEL ARCHITECTURE ###\\n\")\n",
    "                f.write(str(model))\n",
    "                f.write(\"\\n\\n### MODEL SUMMARY ###\\n\")\n",
    "                f.write(str(model_summary))\n",
    "\n",
    "            mlflow.log_artifact(\"model_report.txt\")\n",
    "            logging.info(\"Model report logged to MLflow\")\n",
    "            os.remove(\"model_report.txt\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to log model report: {e}\")\n",
    "            raise\n",
    "    \n",
    "        logging.info(\"Starting training...\")\n",
    "\n",
    "        best_f1 = 0.0\n",
    "        best_save_epoch = 0\n",
    "        train_dir = \"augmented_data/train\"\n",
    "        class_names = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "\n",
    "        for epoch in range(max_num_epochs):\n",
    "            # --- Freezing / unfreezing logic ---\n",
    "            if epoch == 0:\n",
    "                freeze_encoder(model)\n",
    "\n",
    "            if epoch == unfreeze_encoder_at:  # after 20 epochs, unfreeze last few encoder layers\n",
    "                unfreeze_last_layers(model, num_blocks=2)\n",
    "                # lower LR for encoder param group\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    if param_group[\"lr\"] < base_lr:  # encoder group\n",
    "                        param_group[\"lr\"] = base_lr * 0.1\n",
    "                logging.info(\"Adjusted LR for encoder fine-tuning\")\n",
    "            \n",
    "            head_lr    = optimizer.param_groups[0]['lr']\n",
    "            encoder_lr = optimizer.param_groups[1]['lr']\n",
    "\n",
    "            mlflow.log_metric(\"head_lr\", head_lr, step=epoch + 1)\n",
    "            mlflow.log_metric(\"encoder_lr\", encoder_lr, step=epoch + 1)\n",
    "\n",
    "            logging.info(f\"Epoch {epoch+1}, Head LR: {head_lr}, Encoder LR: {encoder_lr}\")\n",
    "\n",
    "\n",
    "            train(model, train_loader, train_criterion, optimizer, device, epoch, class_names)\n",
    "            val_f1 = validate(model, val_loader, val_criterion, device, epoch, class_names)\n",
    "\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                best_save_epoch = epoch\n",
    "                mlflow.pytorch.log_model(model, artifact_path=\"best_model\")\n",
    "                logging.info(f\"Improved F1 (weighted): {val_f1:.6f}. Saved best model.\")\n",
    "\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"latest_model\")\n",
    "\n",
    "            early_stopping(val_f1, model)\n",
    "            if early_stopping.early_stop:\n",
    "                mlflow.log_param(\"best_model_saved_at\", best_save_epoch)\n",
    "                mlflow.log_param(\"early_stopping_triggered_at\", epoch)\n",
    "                logging.warning(\"Early stopping triggered. Stopping training.\")\n",
    "                model.load_state_dict(early_stopping.best_model_state)\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(num_workers=4)  # safer for Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12c631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
